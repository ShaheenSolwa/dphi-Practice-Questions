{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>CheckSum</th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>SizeOfStackCommit</th>\n",
       "      <th>SizeOfHeapReserve</th>\n",
       "      <th>SizeOfHeapCommit</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>NumberOfRvaAndSizes</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>115397</td>\n",
       "      <td>2</td>\n",
       "      <td>33792</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>10485760</td>\n",
       "      <td>40960</td>\n",
       "      <td>6291456</td>\n",
       "      <td>16384</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>142244</td>\n",
       "      <td>2</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>8192</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>60601</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_magic  e_cblp  e_cp  e_crlc  e_cparhdr  e_minalloc  e_maxalloc  e_ss  \\\n",
       "0    23117     144     3       0          4           0       65535     0   \n",
       "1    23117     144     3       0          4           0       65535     0   \n",
       "2    23117     144     3       0          4           0       65535     0   \n",
       "3    23117     144     3       0          4           0       65535     0   \n",
       "4    23117     144     3       0          4           0       65535     0   \n",
       "\n",
       "   e_sp  e_csum  ...    CheckSum  Subsystem  DllCharacteristics  \\\n",
       "0   184       0  ...      115397          2               33792   \n",
       "1   184       0  ...           0          2                   0   \n",
       "2   184       0  ...           0          2                   0   \n",
       "3   184       0  ...      142244          2               33088   \n",
       "4   184       0  ...       60601          2                1024   \n",
       "\n",
       "   SizeOfStackReserve  SizeOfStackCommit  SizeOfHeapReserve  SizeOfHeapCommit  \\\n",
       "0             1048576               4096            1048576              4096   \n",
       "1            10485760              40960            6291456             16384   \n",
       "2             1048576               4096            1048576              4096   \n",
       "3              262144               8192            1048576              4096   \n",
       "4             1048576               4096            1048576              4096   \n",
       "\n",
       "   LoaderFlags  NumberOfRvaAndSizes  class  \n",
       "0            0                   16      1  \n",
       "1            0                   16      1  \n",
       "2            0                   16      0  \n",
       "3            0                   16      0  \n",
       "4            0                   16      0  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/clamp/train_set_label.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(418525865695825)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['class','e_res', 'e_res2'], axis=1)\n",
    "Y = data['class']\n",
    "\n",
    "xData = X.values\n",
    "yData = Y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split( \n",
    "        xData, yData, test_size = 0.1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.94344473007712\n",
      "F1 Score is:  0.9806763285024155\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "model = XGBClassifier()\n",
    "model.fit(xTrain, yTrain)\n",
    "y_pred=model.predict(xTest)\n",
    "print(accuracy_score(yTest, y_pred)*100)\n",
    "print('F1 Score is: ', f1_score(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.94344473007712\n",
      "F1 Score is:  0.9804878048780488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "Clf = RandomForestClassifier(max_depth=100, random_state=0)\n",
    "Clf.fit(xTrain, yTrain)\n",
    "y_pred=Clf.predict(xTest)\n",
    "print(accuracy_score(yTest, y_pred)*100)\n",
    "print('F1 Score is: ', f1_score(yTest, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.00389105, 0.02083333, ..., 0.0625    , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.00389105, 0.02083333, ..., 0.25      , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.00389105, 0.02083333, ..., 0.0625    , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.        , 0.00389105, 0.02083333, ..., 0.0625    , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.00389105, 0.02083333, ..., 0.0625    , 0.        ,\n",
       "        1.        ],\n",
       "       [0.        , 0.00389105, 0.02083333, ..., 0.0625    , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[:, 0:55]\n",
    "Y = dataset[:, 55]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n",
    "\n",
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_scale, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3110 samples, validate on 778 samples\n",
      "Epoch 1/5000\n",
      "3110/3110 [==============================] - 0s 124us/step - loss: 0.6897 - acc: 0.5183 - val_loss: 0.6814 - val_acc: 0.5270\n",
      "Epoch 2/5000\n",
      "3110/3110 [==============================] - 0s 42us/step - loss: 0.6799 - acc: 0.5704 - val_loss: 0.6744 - val_acc: 0.6645\n",
      "Epoch 3/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.6740 - acc: 0.6322 - val_loss: 0.6680 - val_acc: 0.7185\n",
      "Epoch 4/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.6681 - acc: 0.6563 - val_loss: 0.6615 - val_acc: 0.6877\n",
      "Epoch 5/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.6619 - acc: 0.6624 - val_loss: 0.6545 - val_acc: 0.6915\n",
      "Epoch 6/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.6555 - acc: 0.6572 - val_loss: 0.6468 - val_acc: 0.6877\n",
      "Epoch 7/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.6480 - acc: 0.6624 - val_loss: 0.6386 - val_acc: 0.6889\n",
      "Epoch 8/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.6402 - acc: 0.6598 - val_loss: 0.6294 - val_acc: 0.6979\n",
      "Epoch 9/5000\n",
      "3110/3110 [==============================] - 0s 43us/step - loss: 0.6316 - acc: 0.6714 - val_loss: 0.6197 - val_acc: 0.6992\n",
      "Epoch 10/5000\n",
      "3110/3110 [==============================] - 0s 51us/step - loss: 0.6224 - acc: 0.6762 - val_loss: 0.6095 - val_acc: 0.6954\n",
      "Epoch 11/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.6128 - acc: 0.6768 - val_loss: 0.5997 - val_acc: 0.6992\n",
      "Epoch 12/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.6024 - acc: 0.6794 - val_loss: 0.5867 - val_acc: 0.7082\n",
      "Epoch 13/5000\n",
      "3110/3110 [==============================] - 0s 42us/step - loss: 0.5914 - acc: 0.6820 - val_loss: 0.5757 - val_acc: 0.7108\n",
      "Epoch 14/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.5789 - acc: 0.6836 - val_loss: 0.5611 - val_acc: 0.7044\n",
      "Epoch 15/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.5672 - acc: 0.6814 - val_loss: 0.5502 - val_acc: 0.7159\n",
      "Epoch 16/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.5539 - acc: 0.6952 - val_loss: 0.5352 - val_acc: 0.7005\n",
      "Epoch 17/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.5416 - acc: 0.6878 - val_loss: 0.5272 - val_acc: 0.7095\n",
      "Epoch 18/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.5292 - acc: 0.6875 - val_loss: 0.5139 - val_acc: 0.7134\n",
      "Epoch 19/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.5151 - acc: 0.6936 - val_loss: 0.4958 - val_acc: 0.7108\n",
      "Epoch 20/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.5016 - acc: 0.7087 - val_loss: 0.4874 - val_acc: 0.7815\n",
      "Epoch 21/5000\n",
      "3110/3110 [==============================] - 0s 47us/step - loss: 0.4878 - acc: 0.7241 - val_loss: 0.4705 - val_acc: 0.7815\n",
      "Epoch 22/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.4735 - acc: 0.7450 - val_loss: 0.4527 - val_acc: 0.7841\n",
      "Epoch 23/5000\n",
      "3110/3110 [==============================] - 0s 35us/step - loss: 0.4590 - acc: 0.7617 - val_loss: 0.4393 - val_acc: 0.7853\n",
      "Epoch 24/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.4453 - acc: 0.7778 - val_loss: 0.4261 - val_acc: 0.7879\n",
      "Epoch 25/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.4304 - acc: 0.7987 - val_loss: 0.4181 - val_acc: 0.8175\n",
      "Epoch 26/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.4177 - acc: 0.8100 - val_loss: 0.4015 - val_acc: 0.8278\n",
      "Epoch 27/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.4051 - acc: 0.8273 - val_loss: 0.4019 - val_acc: 0.8728\n",
      "Epoch 28/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.3921 - acc: 0.8447 - val_loss: 0.3775 - val_acc: 0.8573\n",
      "Epoch 29/5000\n",
      "3110/3110 [==============================] - 0s 35us/step - loss: 0.3795 - acc: 0.8585 - val_loss: 0.3744 - val_acc: 0.8702\n",
      "Epoch 30/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.3685 - acc: 0.8659 - val_loss: 0.3574 - val_acc: 0.8689\n",
      "Epoch 31/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.3594 - acc: 0.8756 - val_loss: 0.3655 - val_acc: 0.8419\n",
      "Epoch 32/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.3507 - acc: 0.8887 - val_loss: 0.3451 - val_acc: 0.8638\n",
      "Epoch 33/5000\n",
      "3110/3110 [==============================] - 0s 41us/step - loss: 0.3421 - acc: 0.8887 - val_loss: 0.3357 - val_acc: 0.8728\n",
      "Epoch 34/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.3342 - acc: 0.8920 - val_loss: 0.3528 - val_acc: 0.8728\n",
      "Epoch 35/5000\n",
      "3110/3110 [==============================] - 0s 41us/step - loss: 0.3272 - acc: 0.8974 - val_loss: 0.3536 - val_acc: 0.8445\n",
      "Epoch 36/5000\n",
      "3110/3110 [==============================] - 0s 74us/step - loss: 0.3202 - acc: 0.8984 - val_loss: 0.3300 - val_acc: 0.8972\n",
      "Epoch 37/5000\n",
      "3110/3110 [==============================] - 0s 47us/step - loss: 0.3145 - acc: 0.9026 - val_loss: 0.3352 - val_acc: 0.8856\n",
      "Epoch 38/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.3101 - acc: 0.9010 - val_loss: 0.3248 - val_acc: 0.9010\n",
      "Epoch 39/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.3032 - acc: 0.9048 - val_loss: 0.3239 - val_acc: 0.8702\n",
      "Epoch 40/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.3013 - acc: 0.9035 - val_loss: 0.3189 - val_acc: 0.9126\n",
      "Epoch 41/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2961 - acc: 0.9016 - val_loss: 0.3065 - val_acc: 0.8817\n",
      "Epoch 42/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2935 - acc: 0.9026 - val_loss: 0.3049 - val_acc: 0.9177\n",
      "Epoch 43/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2867 - acc: 0.9051 - val_loss: 0.2937 - val_acc: 0.9139\n",
      "Epoch 44/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2850 - acc: 0.9084 - val_loss: 0.3222 - val_acc: 0.8920\n",
      "Epoch 45/5000\n",
      "3110/3110 [==============================] - 0s 35us/step - loss: 0.2837 - acc: 0.9061 - val_loss: 0.2980 - val_acc: 0.9177\n",
      "Epoch 46/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2804 - acc: 0.9074 - val_loss: 0.2799 - val_acc: 0.9165\n",
      "Epoch 47/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2778 - acc: 0.9061 - val_loss: 0.2759 - val_acc: 0.9139\n",
      "Epoch 48/5000\n",
      "3110/3110 [==============================] - 0s 37us/step - loss: 0.2766 - acc: 0.9071 - val_loss: 0.2759 - val_acc: 0.9113\n",
      "Epoch 49/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2728 - acc: 0.9087 - val_loss: 0.2721 - val_acc: 0.9139\n",
      "Epoch 50/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2716 - acc: 0.9100 - val_loss: 0.2947 - val_acc: 0.8946\n",
      "Epoch 51/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2709 - acc: 0.9106 - val_loss: 0.2730 - val_acc: 0.9229\n",
      "Epoch 52/5000\n",
      "3110/3110 [==============================] - 0s 45us/step - loss: 0.2681 - acc: 0.9103 - val_loss: 0.2831 - val_acc: 0.9203\n",
      "Epoch 53/5000\n",
      "3110/3110 [==============================] - 0s 45us/step - loss: 0.2670 - acc: 0.9135 - val_loss: 0.2662 - val_acc: 0.9165\n",
      "Epoch 54/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2662 - acc: 0.9080 - val_loss: 0.2825 - val_acc: 0.9177\n",
      "Epoch 55/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2657 - acc: 0.9096 - val_loss: 0.2794 - val_acc: 0.9126\n",
      "Epoch 56/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2612 - acc: 0.9093 - val_loss: 0.2623 - val_acc: 0.9177\n",
      "Epoch 57/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2627 - acc: 0.9096 - val_loss: 0.2621 - val_acc: 0.9216\n",
      "Epoch 58/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2595 - acc: 0.9084 - val_loss: 0.2575 - val_acc: 0.9165\n",
      "Epoch 59/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2586 - acc: 0.9109 - val_loss: 0.2611 - val_acc: 0.9216\n",
      "Epoch 60/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3110/3110 [==============================] - 0s 48us/step - loss: 0.2583 - acc: 0.9109 - val_loss: 0.2916 - val_acc: 0.9165\n",
      "Epoch 61/5000\n",
      "3110/3110 [==============================] - 0s 35us/step - loss: 0.2604 - acc: 0.9109 - val_loss: 0.2585 - val_acc: 0.9203\n",
      "Epoch 62/5000\n",
      "3110/3110 [==============================] - ETA: 0s - loss: 0.2563 - acc: 0.910 - 0s 38us/step - loss: 0.2566 - acc: 0.9103 - val_loss: 0.2553 - val_acc: 0.9139\n",
      "Epoch 63/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2539 - acc: 0.9106 - val_loss: 0.2542 - val_acc: 0.9139\n",
      "Epoch 64/5000\n",
      "3110/3110 [==============================] - 0s 47us/step - loss: 0.2505 - acc: 0.9135 - val_loss: 0.2610 - val_acc: 0.9190\n",
      "Epoch 65/5000\n",
      "3110/3110 [==============================] - 0s 53us/step - loss: 0.2539 - acc: 0.9113 - val_loss: 0.2602 - val_acc: 0.9177\n",
      "Epoch 66/5000\n",
      "3110/3110 [==============================] - 0s 47us/step - loss: 0.2543 - acc: 0.9093 - val_loss: 0.2501 - val_acc: 0.9139\n",
      "Epoch 67/5000\n",
      "3110/3110 [==============================] - 0s 50us/step - loss: 0.2483 - acc: 0.9109 - val_loss: 0.2780 - val_acc: 0.9062\n",
      "Epoch 68/5000\n",
      "3110/3110 [==============================] - 0s 51us/step - loss: 0.2502 - acc: 0.9103 - val_loss: 0.2545 - val_acc: 0.9177\n",
      "Epoch 69/5000\n",
      "3110/3110 [==============================] - 0s 50us/step - loss: 0.2480 - acc: 0.9138 - val_loss: 0.2824 - val_acc: 0.8817\n",
      "Epoch 70/5000\n",
      "3110/3110 [==============================] - 0s 49us/step - loss: 0.2474 - acc: 0.9109 - val_loss: 0.2572 - val_acc: 0.9190\n",
      "Epoch 71/5000\n",
      "3110/3110 [==============================] - 0s 51us/step - loss: 0.2475 - acc: 0.9132 - val_loss: 0.2397 - val_acc: 0.9203\n",
      "Epoch 72/5000\n",
      "3110/3110 [==============================] - 0s 46us/step - loss: 0.2444 - acc: 0.9148 - val_loss: 0.2389 - val_acc: 0.9216\n",
      "Epoch 73/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2423 - acc: 0.9119 - val_loss: 0.2483 - val_acc: 0.9177\n",
      "Epoch 74/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2434 - acc: 0.9135 - val_loss: 0.2400 - val_acc: 0.9152\n",
      "Epoch 75/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2422 - acc: 0.9141 - val_loss: 0.2493 - val_acc: 0.9177\n",
      "Epoch 76/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2431 - acc: 0.9084 - val_loss: 0.2344 - val_acc: 0.9203\n",
      "Epoch 77/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2402 - acc: 0.9116 - val_loss: 0.3160 - val_acc: 0.8393\n",
      "Epoch 78/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2408 - acc: 0.9119 - val_loss: 0.3045 - val_acc: 0.8920\n",
      "Epoch 79/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2368 - acc: 0.9158 - val_loss: 0.2356 - val_acc: 0.9229\n",
      "Epoch 80/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2389 - acc: 0.9116 - val_loss: 0.3738 - val_acc: 0.8766\n",
      "Epoch 81/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2369 - acc: 0.9132 - val_loss: 0.2839 - val_acc: 0.8740\n",
      "Epoch 82/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2352 - acc: 0.9148 - val_loss: 0.2282 - val_acc: 0.9190\n",
      "Epoch 83/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2370 - acc: 0.9106 - val_loss: 0.2265 - val_acc: 0.9190\n",
      "Epoch 84/5000\n",
      "3110/3110 [==============================] - 0s 43us/step - loss: 0.2353 - acc: 0.9138 - val_loss: 0.2236 - val_acc: 0.9203\n",
      "Epoch 85/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2323 - acc: 0.9129 - val_loss: 0.2381 - val_acc: 0.9254\n",
      "Epoch 86/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2315 - acc: 0.9151 - val_loss: 0.2231 - val_acc: 0.9190\n",
      "Epoch 87/5000\n",
      "3110/3110 [==============================] - 0s 43us/step - loss: 0.2298 - acc: 0.9158 - val_loss: 0.2418 - val_acc: 0.9203\n",
      "Epoch 88/5000\n",
      "3110/3110 [==============================] - 0s 43us/step - loss: 0.2309 - acc: 0.9151 - val_loss: 0.6963 - val_acc: 0.6979\n",
      "Epoch 89/5000\n",
      "3110/3110 [==============================] - 0s 44us/step - loss: 0.2377 - acc: 0.9122 - val_loss: 0.2228 - val_acc: 0.9190\n",
      "Epoch 90/5000\n",
      "3110/3110 [==============================] - 0s 43us/step - loss: 0.2251 - acc: 0.9174 - val_loss: 0.2357 - val_acc: 0.9267\n",
      "Epoch 91/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2284 - acc: 0.9138 - val_loss: 0.2221 - val_acc: 0.9216\n",
      "Epoch 92/5000\n",
      "3110/3110 [==============================] - 0s 35us/step - loss: 0.2272 - acc: 0.9145 - val_loss: 0.5811 - val_acc: 0.7211\n",
      "Epoch 93/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2315 - acc: 0.9106 - val_loss: 0.2150 - val_acc: 0.9254\n",
      "Epoch 94/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2250 - acc: 0.9145 - val_loss: 0.2189 - val_acc: 0.9229\n",
      "Epoch 95/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2248 - acc: 0.9135 - val_loss: 0.2278 - val_acc: 0.9242\n",
      "Epoch 96/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2249 - acc: 0.9125 - val_loss: 0.2164 - val_acc: 0.9254\n",
      "Epoch 97/5000\n",
      "3110/3110 [==============================] - 0s 41us/step - loss: 0.2240 - acc: 0.9158 - val_loss: 0.3347 - val_acc: 0.8856\n",
      "Epoch 98/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2265 - acc: 0.9148 - val_loss: 0.2134 - val_acc: 0.9229\n",
      "Epoch 99/5000\n",
      "3110/3110 [==============================] - 0s 38us/step - loss: 0.2230 - acc: 0.9174 - val_loss: 0.2218 - val_acc: 0.9216\n",
      "Epoch 100/5000\n",
      "3110/3110 [==============================] - 0s 39us/step - loss: 0.2250 - acc: 0.9138 - val_loss: 0.2088 - val_acc: 0.9254\n",
      "Epoch 101/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2254 - acc: 0.9161 - val_loss: 0.2667 - val_acc: 0.8817\n",
      "Epoch 102/5000\n",
      "3110/3110 [==============================] - 0s 40us/step - loss: 0.2214 - acc: 0.9141 - val_loss: 0.2334 - val_acc: 0.9242\n",
      "Epoch 103/5000\n",
      "3110/3110 [==============================] - 0s 36us/step - loss: 0.2291 - acc: 0.9141 - val_loss: 0.2218 - val_acc: 0.9242\n",
      "Epoch 104/5000\n",
      "  32/3110 [..............................] - ETA: 0s - loss: 0.1673 - acc: 0.9688"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-85e343c8d6c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m    \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m55\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m    \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sgd'\u001b[0m\u001b[1;33m,\u001b[0m              \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m              \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2653\u001b[0m                 array_vals.append(\n\u001b[0;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[1;32m-> 2655\u001b[1;33m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "Model = Sequential([    Dense(32, activation='relu', input_shape=(55,)),    Dense(32, activation='relu'),    Dense(1, activation='sigmoid'),])\n",
    "Model.compile(optimizer='sgd',              loss='binary_crossentropy',              metrics=['accuracy'])\n",
    "hist = Model.fit(X_train, Y_train,          batch_size=32, epochs=5000,          validation_data=(X_val, Y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "778/778 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2163755752356929, 0.9241645241151432]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model.evaluate(X_val, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('https://raw.githubusercontent.com/dphi-official/Datasets/master/clamp/test_set_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e_magic</th>\n",
       "      <th>e_cblp</th>\n",
       "      <th>e_cp</th>\n",
       "      <th>e_crlc</th>\n",
       "      <th>e_cparhdr</th>\n",
       "      <th>e_minalloc</th>\n",
       "      <th>e_maxalloc</th>\n",
       "      <th>e_ss</th>\n",
       "      <th>e_sp</th>\n",
       "      <th>e_csum</th>\n",
       "      <th>...</th>\n",
       "      <th>SizeOfHeaders</th>\n",
       "      <th>CheckSum</th>\n",
       "      <th>Subsystem</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>SizeOfStackCommit</th>\n",
       "      <th>SizeOfHeapReserve</th>\n",
       "      <th>SizeOfHeapCommit</th>\n",
       "      <th>LoaderFlags</th>\n",
       "      <th>NumberOfRvaAndSizes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>512</td>\n",
       "      <td>54759</td>\n",
       "      <td>2</td>\n",
       "      <td>1024</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23117</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>16384</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23117</td>\n",
       "      <td>144</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>65535</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1024</td>\n",
       "      <td>148592</td>\n",
       "      <td>2</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>8192</td>\n",
       "      <td>1048576</td>\n",
       "      <td>4096</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   e_magic  e_cblp  e_cp  e_crlc  e_cparhdr  e_minalloc  e_maxalloc  e_ss  \\\n",
       "0    23117     144     3       0          4           0       65535     0   \n",
       "1    23117     144     3       0          4           0       65535     0   \n",
       "2    23117     144     3       0          4           0       65535     0   \n",
       "3    23117      80     2       0          4          15       65535     0   \n",
       "4    23117     144     3       0          4           0       65535     0   \n",
       "\n",
       "   e_sp  e_csum         ...           SizeOfHeaders  CheckSum  Subsystem  \\\n",
       "0   184       0         ...                    1024         0          2   \n",
       "1   184       0         ...                    4096         0          2   \n",
       "2   184       0         ...                     512     54759          2   \n",
       "3   184       0         ...                    1024         0          2   \n",
       "4   184       0         ...                    1024    148592          2   \n",
       "\n",
       "   DllCharacteristics  SizeOfStackReserve  SizeOfStackCommit  \\\n",
       "0               32768             1048576               4096   \n",
       "1                   0             1048576               4096   \n",
       "2                1024             1048576               4096   \n",
       "3                   0             1048576              16384   \n",
       "4               33088              262144               8192   \n",
       "\n",
       "   SizeOfHeapReserve  SizeOfHeapCommit  LoaderFlags  NumberOfRvaAndSizes  \n",
       "0            1048576              4096            0                   16  \n",
       "1            1048576              4096            0                   16  \n",
       "2            1048576              4096            0                   16  \n",
       "3            1048576              4096            0                   16  \n",
       "4            1048576              4096            0                   16  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = test.drop(['e_res', 'e_res2'], axis=1)\n",
    "vals = model.predict(test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(vals)\n",
    "res.columns = [\"prediction\"]\n",
    "res.to_csv(\"clamp.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
