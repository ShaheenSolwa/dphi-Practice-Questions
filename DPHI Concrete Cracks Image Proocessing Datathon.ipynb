{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\shahe\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Data analysis and manipultion tool\n",
    "import numpy as np # Fundamental package for linear algebra and multidimensional arrays\n",
    "import tensorflow as tf # Deep Learning Tool\n",
    "import os # OS module in Python provides a way of using operating system dependent functionality\n",
    "import cv2 # Library for image processing\n",
    "from sklearn.model_selection import train_test_split # For splitting the data into train and validation set\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2c7218042ff5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mcreate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-2c7218042ff5>\u001b[0m in \u001b[0;36mcreate_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# os.listdir gets you all the list of name of files located in the given path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                 \u001b[0mimg_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# converts the image to pixels and gray scales the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m                 \u001b[0mnew_img_array\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# resizing the images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'Negative'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "img_size=100 # Here we are taking image size as 100, but it's on you. You can take 50 or 40 or 32 and so on\n",
    "def create_data():\n",
    "    for item in ['Negative','Positive']:\n",
    "        path='C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DPHI Image Pred Cracks/train/'+item+\"/\"\n",
    "\n",
    "        for img in os.listdir(path): # os.listdir gets you all the list of name of files located in the given path\n",
    "            try:\n",
    "                img_array=cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE) # converts the image to pixels and gray scales the images\n",
    "                new_img_array=cv2.resize(img_array,(img_size,img_size)) # resizing the images\n",
    "                if item == 'Negative':\n",
    "                    data.append([new_img_array,0])\n",
    "                else:\n",
    "                    data.append([new_img_array, 1]) # appending the list of image pixels and respective target value (i.e. animal type) in data\n",
    "            except Exception as e:\n",
    "                    pass # try and except is exception handling case in python, saves you from getting errors\n",
    "\n",
    "\n",
    "create_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "x = []\n",
    "y = []\n",
    "for image in data:\n",
    "    x.append(image[0])\n",
    "    y.append(image[1])\n",
    "\n",
    "# converting x & y to numpy array as they are list\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25846/25846 [==============================] - 4s 171us/sample - loss: 27.1518 - acc: 0.5650\n",
      "Epoch 2/100\n",
      "25846/25846 [==============================] - 4s 168us/sample - loss: 4.1682 - acc: 0.7026\n",
      "Epoch 3/100\n",
      "25846/25846 [==============================] - 4s 170us/sample - loss: 3.0589 - acc: 0.7126\n",
      "Epoch 4/100\n",
      "25846/25846 [==============================] - 4s 165us/sample - loss: 3.4140 - acc: 0.7038\n",
      "Epoch 5/100\n",
      "25846/25846 [==============================] - 4s 164us/sample - loss: 1.9198 - acc: 0.7540\n",
      "Epoch 6/100\n",
      "25846/25846 [==============================] - 4s 165us/sample - loss: 1.2043 - acc: 0.7576\n",
      "Epoch 7/100\n",
      "25846/25846 [==============================] - 4s 171us/sample - loss: 0.5508 - acc: 0.8266\n",
      "Epoch 8/100\n",
      "25846/25846 [==============================] - 4s 164us/sample - loss: 0.8618 - acc: 0.8009\n",
      "Epoch 9/100\n",
      "25846/25846 [==============================] - 4s 165us/sample - loss: 0.6533 - acc: 0.8106\n",
      "Epoch 10/100\n",
      "25846/25846 [==============================] - 4s 164us/sample - loss: 0.4142 - acc: 0.8507\n",
      "Epoch 11/100\n",
      "25846/25846 [==============================] - 4s 171us/sample - loss: 0.3411 - acc: 0.8672\n",
      "Epoch 12/100\n",
      "25846/25846 [==============================] - 4s 164us/sample - loss: 0.4200 - acc: 0.8503\n",
      "Epoch 13/100\n",
      "25846/25846 [==============================] - 4s 166us/sample - loss: 0.3824 - acc: 0.8450\n",
      "Epoch 14/100\n",
      "25846/25846 [==============================] - 4s 170us/sample - loss: 0.3034 - acc: 0.8787s - lo\n",
      "Epoch 15/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3387 - acc: 0.8551\n",
      "Epoch 16/100\n",
      "25846/25846 [==============================] - 5s 187us/sample - loss: 0.3348 - acc: 0.8604\n",
      "Epoch 17/100\n",
      "25846/25846 [==============================] - 5s 189us/sample - loss: 0.3651 - acc: 0.7945\n",
      "Epoch 18/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.4421 - acc: 0.7752\n",
      "Epoch 19/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3998 - acc: 0.8275\n",
      "Epoch 20/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.3910 - acc: 0.8311\n",
      "Epoch 21/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.3678 - acc: 0.8447\n",
      "Epoch 22/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3691 - acc: 0.8426\n",
      "Epoch 23/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.4053 - acc: 0.8182\n",
      "Epoch 24/100\n",
      "25846/25846 [==============================] - 5s 189us/sample - loss: 0.3745 - acc: 0.8405\n",
      "Epoch 25/100\n",
      "25846/25846 [==============================] - 5s 187us/sample - loss: 0.4029 - acc: 0.8227\n",
      "Epoch 26/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3375 - acc: 0.8652\n",
      "Epoch 27/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3560 - acc: 0.8515\n",
      "Epoch 28/100\n",
      "25846/25846 [==============================] - 5s 206us/sample - loss: 0.3751 - acc: 0.8408\n",
      "Epoch 29/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3886 - acc: 0.8332\n",
      "Epoch 30/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.3686 - acc: 0.8438\n",
      "Epoch 31/100\n",
      "25846/25846 [==============================] - 5s 194us/sample - loss: 0.3844 - acc: 0.8344\n",
      "Epoch 32/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3721 - acc: 0.8452\n",
      "Epoch 33/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3363 - acc: 0.8645\n",
      "Epoch 34/100\n",
      "25846/25846 [==============================] - 5s 195us/sample - loss: 0.3694 - acc: 0.8453\n",
      "Epoch 35/100\n",
      "25846/25846 [==============================] - 5s 187us/sample - loss: 0.4093 - acc: 0.8182\n",
      "Epoch 36/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.4061 - acc: 0.8202\n",
      "Epoch 37/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3631 - acc: 0.8503\n",
      "Epoch 38/100\n",
      "25846/25846 [==============================] - 5s 191us/sample - loss: 0.3863 - acc: 0.8356\n",
      "Epoch 39/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.3375 - acc: 0.8670\n",
      "Epoch 40/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3793 - acc: 0.8424\n",
      "Epoch 41/100\n",
      "25846/25846 [==============================] - 5s 193us/sample - loss: 0.3868 - acc: 0.8350\n",
      "Epoch 42/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3598 - acc: 0.8514\n",
      "Epoch 43/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3702 - acc: 0.8466\n",
      "Epoch 44/100\n",
      "25846/25846 [==============================] - 5s 199us/sample - loss: 0.3303 - acc: 0.8719\n",
      "Epoch 45/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3634 - acc: 0.8515\n",
      "Epoch 46/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3872 - acc: 0.8330\n",
      "Epoch 47/100\n",
      "25846/25846 [==============================] - 5s 187us/sample - loss: 0.3639 - acc: 0.8506\n",
      "Epoch 48/100\n",
      "25846/25846 [==============================] - 5s 189us/sample - loss: 0.3347 - acc: 0.8585\n",
      "Epoch 49/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3216 - acc: 0.8737\n",
      "Epoch 50/100\n",
      "25846/25846 [==============================] - 5s 183us/sample - loss: 0.3352 - acc: 0.8676\n",
      "Epoch 51/100\n",
      "25846/25846 [==============================] - 5s 194us/sample - loss: 0.3713 - acc: 0.8461\n",
      "Epoch 52/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3280 - acc: 0.8706\n",
      "Epoch 53/100\n",
      "25846/25846 [==============================] - 5s 185us/sample - loss: 0.4117 - acc: 0.8197\n",
      "Epoch 54/100\n",
      "25846/25846 [==============================] - 5s 196us/sample - loss: 0.3601 - acc: 0.8498\n",
      "Epoch 55/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.3425 - acc: 0.8618\n",
      "Epoch 56/100\n",
      "25846/25846 [==============================] - 5s 206us/sample - loss: 0.3734 - acc: 0.8459\n",
      "Epoch 57/100\n",
      "25846/25846 [==============================] - 5s 198us/sample - loss: 0.3715 - acc: 0.8407\n",
      "Epoch 58/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3318 - acc: 0.8665\n",
      "Epoch 59/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3153 - acc: 0.8762\n",
      "Epoch 60/100\n",
      "25846/25846 [==============================] - 5s 185us/sample - loss: 0.3599 - acc: 0.8512\n",
      "Epoch 61/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.3250 - acc: 0.8734\n",
      "Epoch 62/100\n",
      "25846/25846 [==============================] - ETA: 0s - loss: 0.3592 - acc: 0.852 - 5s 190us/sample - loss: 0.3593 - acc: 0.8530\n",
      "Epoch 63/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3360 - acc: 0.8667\n",
      "Epoch 64/100\n",
      "25846/25846 [==============================] - 5s 195us/sample - loss: 0.3553 - acc: 0.8534\n",
      "Epoch 65/100\n",
      "25846/25846 [==============================] - 5s 190us/sample - loss: 0.3847 - acc: 0.8356\n",
      "Epoch 66/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3205 - acc: 0.8748\n",
      "Epoch 67/100\n",
      "25846/25846 [==============================] - 5s 195us/sample - loss: 0.3779 - acc: 0.8408\n",
      "Epoch 68/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3292 - acc: 0.8699\n",
      "Epoch 69/100\n",
      "25846/25846 [==============================] - 5s 185us/sample - loss: 0.3770 - acc: 0.8434\n",
      "Epoch 70/100\n",
      "25846/25846 [==============================] - 5s 191us/sample - loss: 0.3254 - acc: 0.8723\n",
      "Epoch 71/100\n",
      "25846/25846 [==============================] - 5s 189us/sample - loss: 0.3894 - acc: 0.8368\n",
      "Epoch 72/100\n",
      "25846/25846 [==============================] - 5s 193us/sample - loss: 0.3409 - acc: 0.8637\n",
      "Epoch 73/100\n",
      "25846/25846 [==============================] - 5s 185us/sample - loss: 0.3299 - acc: 0.8692\n",
      "Epoch 74/100\n",
      "25846/25846 [==============================] - 5s 195us/sample - loss: 0.3633 - acc: 0.8513\n",
      "Epoch 75/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3396 - acc: 0.8627\n",
      "Epoch 76/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3401 - acc: 0.8644\n",
      "Epoch 77/100\n",
      "25846/25846 [==============================] - 5s 199us/sample - loss: 0.3354 - acc: 0.8650\n",
      "Epoch 78/100\n",
      "25846/25846 [==============================] - 5s 180us/sample - loss: 0.3305 - acc: 0.8691\n",
      "Epoch 79/100\n",
      "25846/25846 [==============================] - 5s 180us/sample - loss: 0.3357 - acc: 0.8638\n",
      "Epoch 80/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.3447 - acc: 0.8618\n",
      "Epoch 81/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3376 - acc: 0.8644\n",
      "Epoch 82/100\n",
      "25846/25846 [==============================] - 5s 186us/sample - loss: 0.3178 - acc: 0.8755\n",
      "Epoch 83/100\n",
      "25846/25846 [==============================] - 5s 185us/sample - loss: 0.3529 - acc: 0.8558\n",
      "Epoch 84/100\n",
      "25846/25846 [==============================] - 5s 189us/sample - loss: 0.3198 - acc: 0.8744\n",
      "Epoch 85/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3125 - acc: 0.8774\n",
      "Epoch 86/100\n",
      "25846/25846 [==============================] - 5s 188us/sample - loss: 0.3240 - acc: 0.8722\n",
      "Epoch 87/100\n",
      "25846/25846 [==============================] - 5s 190us/sample - loss: 0.3128 - acc: 0.8791\n",
      "Epoch 88/100\n",
      "25846/25846 [==============================] - 5s 182us/sample - loss: 0.3729 - acc: 0.8474\n",
      "Epoch 89/100\n",
      "25846/25846 [==============================] - 5s 188us/sample - loss: 0.3477 - acc: 0.8576s - loss: 0.3445 -\n",
      "Epoch 90/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.3485 - acc: 0.8580\n",
      "Epoch 91/100\n",
      "25846/25846 [==============================] - 5s 198us/sample - loss: 0.3258 - acc: 0.8718\n",
      "Epoch 92/100\n",
      "25846/25846 [==============================] - 5s 180us/sample - loss: 0.3282 - acc: 0.8693\n",
      "Epoch 93/100\n",
      "25846/25846 [==============================] - 5s 184us/sample - loss: 0.3305 - acc: 0.8719\n",
      "Epoch 94/100\n",
      "25846/25846 [==============================] - 5s 195us/sample - loss: 0.3227 - acc: 0.8756s - loss: 0.\n",
      "Epoch 95/100\n",
      "25846/25846 [==============================] - 5s 192us/sample - loss: 0.3125 - acc: 0.8799\n",
      "Epoch 96/100\n",
      "25846/25846 [==============================] - 5s 191us/sample - loss: 0.2965 - acc: 0.8892\n",
      "Epoch 97/100\n",
      "25846/25846 [==============================] - 5s 211us/sample - loss: 0.3008 - acc: 0.8843\n",
      "Epoch 98/100\n",
      "25846/25846 [==============================] - 5s 198us/sample - loss: 0.3246 - acc: 0.8743\n",
      "Epoch 99/100\n",
      "25846/25846 [==============================] - 5s 197us/sample - loss: 0.3201 - acc: 0.8756\n",
      "Epoch 100/100\n",
      "25846/25846 [==============================] - 5s 203us/sample - loss: 0.3034 - acc: 0.8857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x186bb1b57b8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Flatten(input_shape=(100, 100)), # flattening the image\n",
    "tf.keras.layers.Dense(100, activation='relu'),\n",
    "tf.keras.layers.Dense(100, activation='relu'),  \n",
    "tf.keras.layers.Dense(50, activation='relu'),\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='Adamax',\n",
    "loss='binary_crossentropy',\n",
    "metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2872/2872 [==============================] - 0s 174us/sample - loss: 0.4200 - acc: 0.8269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4200075967730254, 0.82694983]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename\n",
       "0  Image_1.jpg\n",
       "1  Image_2.jpg\n",
       "2  Image_3.jpg\n",
       "3  Image_4.jpg\n",
       "4  Image_5.jpg"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_order = pd.read_csv(r\"C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DPHI Image Pred Cracks/Testing_set_concrete_crack.csv\")\n",
    "test_image_order.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [[fname, r\"C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DPHI Image Pred Cracks/test/\" + fname] for fname in test_image_order['filename']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of image names i.e.  11282 matches the number of file paths i.e.  11282\n"
     ]
    }
   ],
   "source": [
    "if len(test_image_order) == len(file_paths):\n",
    "    print('Number of image names i.e. ', len(test_image_order), 'matches the number of file paths i.e. ', len(file_paths))\n",
    "else:\n",
    "    print('Number of image names does not match the number of filepaths')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>filepaths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image_1.jpg</td>\n",
       "      <td>C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Image_2.jpg</td>\n",
       "      <td>C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Image_3.jpg</td>\n",
       "      <td>C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Image_4.jpg</td>\n",
       "      <td>C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Image_5.jpg</td>\n",
       "      <td>C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          filepaths\n",
       "0  Image_1.jpg  C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...\n",
       "1  Image_2.jpg  C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...\n",
       "2  Image_3.jpg  C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...\n",
       "3  Image_4.jpg  C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP...\n",
       "4  Image_5.jpg  C:/Users/shahe/AI PROJECTS/IMAGE PROCESSING/DP..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = pd.DataFrame(file_paths, columns=['filename', 'filepaths'])\n",
    "test_images.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[203 206 208 ... 202 202 202]\n",
      " [204 206 208 ... 203 203 203]\n",
      " [205 207 208 ... 205 205 205]\n",
      " ...\n",
      " [208 208 209 ... 200 202 203]\n",
      " [208 208 209 ... 205 207 209]\n",
      " [208 208 209 ... 208 210 212]]\n",
      "[[181 185 185 ... 210 210 210]\n",
      " [183 187 188 ... 211 211 211]\n",
      " [184 188 191 ... 207 207 207]\n",
      " ...\n",
      " [187 184 181 ... 177 186 192]\n",
      " [187 184 181 ... 180 188 194]\n",
      " [187 184 181 ... 182 191 197]]\n",
      "[[154 158 163 ... 159 156 153]\n",
      " [153 157 162 ... 162 159 157]\n",
      " [153 157 161 ... 164 161 159]\n",
      " ...\n",
      " [150 151 153 ... 151 154 157]\n",
      " [150 152 153 ... 153 156 159]\n",
      " [150 152 153 ... 155 158 161]]\n",
      "[[152 148 145 ... 145 145 145]\n",
      " [150 148 146 ... 142 142 142]\n",
      " [148 147 147 ... 146 146 146]\n",
      " ...\n",
      " [150 153 154 ... 140 141 142]\n",
      " [150 153 154 ... 140 141 142]\n",
      " [150 153 154 ... 142 143 144]]\n",
      "[[186 189 192 ... 191 191 191]\n",
      " [187 190 193 ... 190 190 190]\n",
      " [189 192 195 ... 190 190 190]\n",
      " ...\n",
      " [223 220 215 ... 183 183 183]\n",
      " [210 208 204 ... 185 185 185]\n",
      " [200 198 196 ... 188 188 188]]\n",
      "[[188 189 190 ... 176 178 180]\n",
      " [190 190 190 ... 178 180 182]\n",
      " [193 192 192 ... 181 183 185]\n",
      " ...\n",
      " [176 176 177 ... 180 181 182]\n",
      " [179 179 180 ... 180 181 182]\n",
      " [182 182 183 ... 180 181 182]]\n",
      "[[184 186 188 ... 188 188 188]\n",
      " [184 186 187 ... 188 188 188]\n",
      " [185 185 186 ... 189 189 189]\n",
      " ...\n",
      " [173 172 171 ...  60  61  61]\n",
      " [174 173 172 ...  61  61  62]\n",
      " [175 174 173 ...  62  62  63]]\n",
      "[[175 176 176 ... 149 149 149]\n",
      " [177 177 177 ... 146 146 146]\n",
      " [179 180 179 ... 151 151 151]\n",
      " ...\n",
      " [139 141 140 ... 175 178 181]\n",
      " [137 139 138 ... 175 178 181]\n",
      " [135 137 136 ... 175 178 181]]\n",
      "[[183 184 185 ... 193 193 193]\n",
      " [186 186 185 ... 192 192 192]\n",
      " [190 188 186 ... 191 191 191]\n",
      " ...\n",
      " [176 176 177 ... 199 199 199]\n",
      " [178 179 179 ... 199 199 199]\n",
      " [180 181 181 ... 199 199 199]]\n",
      "[[199 198 196 ... 207 207 207]\n",
      " [197 197 196 ... 207 207 207]\n",
      " [194 195 196 ... 207 207 207]\n",
      " ...\n",
      " [206 206 205 ... 208 208 208]\n",
      " [205 205 204 ... 208 208 208]\n",
      " [204 204 204 ... 208 208 208]]\n",
      "[[170 172 175 ... 194 194 192]\n",
      " [173 174 176 ... 195 194 193]\n",
      " [176 176 176 ... 194 193 192]\n",
      " ...\n",
      " [194 195 194 ... 188 188 188]\n",
      " [194 195 194 ... 186 186 186]\n",
      " [194 195 194 ... 184 184 184]]\n",
      "[[185 184 184 ... 180 181 181]\n",
      " [189 187 184 ... 180 180 181]\n",
      " [193 189 184 ... 182 183 183]\n",
      " ...\n",
      " [188 188 188 ... 182 172 165]\n",
      " [188 188 188 ... 182 172 165]\n",
      " [188 188 188 ... 182 172 165]]\n",
      "[[153 158 162 ... 171 170 170]\n",
      " [152 156 161 ... 170 170 169]\n",
      " [154 159 164 ... 169 169 169]\n",
      " ...\n",
      " [157 157 155 ... 167 165 163]\n",
      " [159 159 157 ... 166 164 162]\n",
      " [161 161 159 ... 165 163 161]]\n",
      "[[156 159 162 ... 178 178 178]\n",
      " [155 155 155 ... 178 178 178]\n",
      " [156 153 151 ... 179 179 179]\n",
      " ...\n",
      " [189 192 193 ... 185 185 185]\n",
      " [189 192 193 ... 185 185 185]\n",
      " [189 192 193 ... 185 185 185]]\n",
      "[[166 165 163 ... 166 167 169]\n",
      " [168 166 163 ... 167 168 169]\n",
      " [171 168 165 ... 169 169 170]\n",
      " ...\n",
      " [174 174 174 ... 155 153 152]\n",
      " [174 174 174 ... 159 158 156]\n",
      " [174 174 174 ... 162 160 159]]\n",
      "[[216 217 216 ... 214 214 214]\n",
      " [215 215 215 ... 213 213 213]\n",
      " [214 214 213 ... 211 211 212]\n",
      " ...\n",
      " [209 210 211 ... 205 202 199]\n",
      " [209 210 211 ... 205 202 199]\n",
      " [209 210 211 ... 205 202 199]]\n",
      "[[198 198 196 ... 198 198 198]\n",
      " [198 197 196 ... 198 198 198]\n",
      " [197 197 196 ... 199 199 199]\n",
      " ...\n",
      " [191 188 185 ... 191 191 191]\n",
      " [191 188 185 ... 191 191 191]\n",
      " [191 188 185 ... 191 191 191]]\n",
      "[[ 52  52  52 ... 192 192 192]\n",
      " [ 52  52  51 ... 190 190 190]\n",
      " [ 56  56  56 ... 189 189 189]\n",
      " ...\n",
      " [209 206 202 ... 199 200 201]\n",
      " [207 204 200 ... 201 202 203]\n",
      " [205 202 198 ... 203 204 205]]\n",
      "[[184 186 186 ... 186 186 186]\n",
      " [183 185 186 ... 187 187 187]\n",
      " [183 185 187 ... 187 187 187]\n",
      " ...\n",
      " [187 188 188 ... 188 188 188]\n",
      " [187 188 188 ... 188 188 188]\n",
      " [187 188 188 ... 188 188 188]]\n",
      "[[173 176 179 ... 180 182 183]\n",
      " [176 177 178 ... 180 181 181]\n",
      " [179 178 176 ... 181 181 180]\n",
      " ...\n",
      " [185 182 178 ... 180 180 180]\n",
      " [185 182 178 ... 182 182 182]\n",
      " [185 182 178 ... 185 185 185]]\n",
      "[[217 215 213 ... 213 213 213]\n",
      " [216 215 212 ... 211 211 211]\n",
      " [215 214 211 ... 210 210 210]\n",
      " ...\n",
      " [206 208 208 ... 211 207 203]\n",
      " [206 208 208 ... 211 207 203]\n",
      " [206 208 208 ... 211 207 203]]\n",
      "[[219 214 210 ... 203 205 207]\n",
      " [218 213 210 ... 203 204 206]\n",
      " [216 212 210 ... 203 204 206]\n",
      " ...\n",
      " [218 219 220 ... 177 180 183]\n",
      " [218 219 220 ... 177 180 183]\n",
      " [218 219 220 ... 177 180 183]]\n",
      "[[188 193 199 ... 195 194 193]\n",
      " [195 200 205 ... 194 193 192]\n",
      " [202 205 208 ... 194 193 192]\n",
      " ...\n",
      " [195 195 195 ... 189 188 187]\n",
      " [203 203 203 ... 188 187 186]\n",
      " [209 209 209 ... 187 186 185]]\n",
      "[[190 188 185 ... 184 184 184]\n",
      " [189 187 184 ... 183 183 183]\n",
      " [186 184 182 ... 183 183 183]\n",
      " ...\n",
      " [172 167 161 ... 173 175 177]\n",
      " [172 168 163 ... 173 175 177]\n",
      " [171 168 165 ... 173 175 177]]\n",
      "[[146 155 164 ... 165 166 167]\n",
      " [147 155 164 ... 166 167 168]\n",
      " [149 156 163 ... 167 168 169]\n",
      " ...\n",
      " [153 153 152 ... 137 141 145]\n",
      " [154 153 153 ... 137 141 145]\n",
      " [155 154 154 ... 137 141 145]]\n",
      "[[212 213 214 ... 194 192 191]\n",
      " [208 209 211 ... 196 194 192]\n",
      " [205 206 208 ... 201 198 195]\n",
      " ...\n",
      " [192 184 184 ... 209 210 211]\n",
      " [186 179 181 ... 209 210 211]\n",
      " [180 175 179 ... 209 210 211]]\n",
      "[[179 184 182 ... 168 167 166]\n",
      " [175 180 180 ... 169 168 167]\n",
      " [169 175 177 ... 170 169 168]\n",
      " ...\n",
      " [172 171 172 ... 184 186 189]\n",
      " [172 171 172 ... 183 186 188]\n",
      " [173 172 172 ... 183 186 188]]\n",
      "[[181 183 185 ... 167 170 173]\n",
      " [179 182 184 ... 163 167 169]\n",
      " [178 181 184 ... 159 162 165]\n",
      " ...\n",
      " [178 180 182 ... 191 191 191]\n",
      " [181 183 185 ... 194 194 194]\n",
      " [183 186 188 ... 197 197 197]]\n",
      "[[207 205 202 ... 210 210 210]\n",
      " [206 204 202 ... 210 210 210]\n",
      " [206 204 202 ... 210 210 210]\n",
      " ...\n",
      " [203 204 204 ... 197 199 201]\n",
      " [203 204 204 ... 197 199 201]\n",
      " [203 204 204 ... 197 199 201]]\n",
      "[[187 186 186 ... 185 184 183]\n",
      " [186 187 188 ... 184 183 182]\n",
      " [185 188 191 ... 183 182 181]\n",
      " ...\n",
      " [184 185 186 ... 185 185 185]\n",
      " [184 185 186 ... 186 186 186]\n",
      " [184 185 186 ... 187 187 187]]\n",
      "[[173 172 170 ... 155 153 151]\n",
      " [174 172 169 ... 153 151 149]\n",
      " [175 171 167 ... 150 148 146]\n",
      " ...\n",
      " [165 165 166 ... 162 162 162]\n",
      " [166 166 167 ... 160 160 160]\n",
      " [167 167 169 ... 158 158 158]]\n",
      "[[188 186 184 ... 197 196 195]\n",
      " [187 185 183 ... 196 195 194]\n",
      " [186 184 183 ... 197 196 196]\n",
      " ...\n",
      " [199 201 204 ... 115 114 114]\n",
      " [198 199 201 ... 129 129 128]\n",
      " [197 198 198 ... 140 139 139]]\n",
      "[[228 228 228 ... 203 203 203]\n",
      " [223 225 226 ... 203 203 203]\n",
      " [218 221 225 ... 204 204 204]\n",
      " ...\n",
      " [192 187 185 ... 204 192 183]\n",
      " [194 189 187 ... 198 186 178]\n",
      " [196 191 189 ... 195 182 174]]\n",
      "[[188 185 183 ... 169 171 173]\n",
      " [190 189 189 ... 167 169 171]\n",
      " [189 189 191 ... 164 166 168]\n",
      " ...\n",
      " [194 194 192 ... 190 190 190]\n",
      " [193 193 192 ... 188 188 188]\n",
      " [193 193 192 ... 186 186 186]]\n",
      "[[192 186 182 ... 203 198 193]\n",
      " [191 186 181 ... 196 192 187]\n",
      " [195 190 184 ... 192 187 183]\n",
      " ...\n",
      " [192 192 197 ... 188 186 184]\n",
      " [194 192 193 ... 188 186 184]\n",
      " [196 191 189 ... 188 186 184]]\n",
      "[[217 214 212 ... 216 217 218]\n",
      " [218 215 213 ... 216 217 218]\n",
      " [220 218 216 ... 216 216 217]\n",
      " ...\n",
      " [214 216 218 ... 229 228 227]\n",
      " [214 216 218 ... 229 228 227]\n",
      " [214 216 218 ... 229 228 227]]\n",
      "[[204 203 201 ... 193 194 195]\n",
      " [204 204 203 ... 194 195 196]\n",
      " [204 204 205 ... 196 196 197]\n",
      " ...\n",
      " [196 194 193 ... 174 171 168]\n",
      " [193 192 191 ... 176 173 170]\n",
      " [191 190 189 ... 178 175 172]]\n",
      "[[160 161 162 ... 169 169 169]\n",
      " [157 157 156 ... 168 168 168]\n",
      " [155 154 151 ... 168 168 168]\n",
      " ...\n",
      " [195 194 194 ... 175 177 179]\n",
      " [195 194 194 ... 175 177 179]\n",
      " [195 194 194 ... 175 177 179]]\n",
      "[[147 147 148 ... 171 171 171]\n",
      " [149 148 148 ... 172 172 172]\n",
      " [153 151 150 ... 175 175 175]\n",
      " ...\n",
      " [170 169 161 ... 170 172 173]\n",
      " [173 172 166 ... 170 172 173]\n",
      " [174 174 169 ... 170 172 173]]\n",
      "[[160 156 154 ... 155 156 157]\n",
      " [160 157 155 ... 154 155 156]\n",
      " [160 158 156 ... 153 154 155]\n",
      " ...\n",
      " [182 183 184 ... 161 165 169]\n",
      " [179 181 182 ... 161 165 169]\n",
      " [177 179 179 ... 161 165 169]]\n",
      "[[201 201 201 ... 204 204 205]\n",
      " [198 199 199 ... 205 204 204]\n",
      " [195 196 196 ... 200 198 197]\n",
      " ...\n",
      " [198 202 205 ... 176 179 182]\n",
      " [185 189 193 ... 176 179 182]\n",
      " [176 178 183 ... 176 179 182]]\n"
     ]
    }
   ],
   "source": [
    "test_pixel_data = [] # initialize an empty numpy array\n",
    "image_size = 100 # image size taken is 100 here. one can take other size too\n",
    "for i in range(len(test_images)):\n",
    "    img_array = cv2.imread(test_images['filepaths'][i], cv2.IMREAD_GRAYSCALE) # converting the image to gray scale\n",
    "    new_img_array = cv2.resize(img_array, (image_size, image_size)) # resizing the image array\n",
    "    test_pixel_data.append(new_img_array)\n",
    "test_pixel_data = np.array(test_pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "When using data tensors as input to a model, you should specify the `steps` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-1ec956a4c809>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pixel_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1058\u001b[0m     \u001b[1;31m# generate symbolic tensors).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1059\u001b[0m     x, _, _ = self._standardize_user_data(\n\u001b[1;32m-> 1060\u001b[1;33m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0m\u001b[0;32m   1061\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2507\u001b[0m     \u001b[1;31m# Validates `steps` argument based on x's type.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2508\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcheck_steps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2509\u001b[1;33m       \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_steps_argument\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2510\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2511\u001b[0m     \u001b[1;31m# First, we build/compile the model on the fly if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_steps_argument\u001b[1;34m(input_data, steps, steps_name)\u001b[0m\n\u001b[0;32m    988\u001b[0m       raise ValueError('When using {input_type} as input to a model, you should'\n\u001b[0;32m    989\u001b[0m                        ' specify the `{steps_name}` argument.'.format(\n\u001b[1;32m--> 990\u001b[1;33m                            input_type=input_type_str, steps_name=steps_name))\n\u001b[0m\u001b[0;32m    991\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: When using data tensors as input to a model, you should specify the `steps` argument."
     ]
    }
   ],
   "source": [
    "pred = model.predict(test_pixel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for value in pred:\n",
    "    if value < 0.5:\n",
    "        prediction.append(\"Negative\")\n",
    "    else:\n",
    "        prediction.append(\"Positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame({'prediction': prediction}) # prediction is nothing but the final predictions of your model on input features of your new unseen test data\n",
    "res.to_csv(\"ConcreteSub.csv\", index = False) # the csv file will be saved locally on the same location where this notebook is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
